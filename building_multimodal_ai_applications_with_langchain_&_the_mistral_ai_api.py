# -*- coding: utf-8 -*-
"""Building Multimodal AI Applications with LangChain & the mistral ai  API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B-F4J95eVIsFWPgM4BeUXGmGcIpfMFIG

# YouTube Q&A Bot Using Free APIs
Features:

‚úÖ Extracts YouTube transcripts (No API key required).

‚úÖ Embeds transcript using Hugging Face (Free).

‚úÖ Stores embeddings in FAISS (Fast vector search).

‚úÖ Answers questions using Mistral AI API (Free).

# üîπ Step 1: Install Required Libraries
"""

pip install yt-dlp youtube-transcript-api langchain sentence-transformers faiss-cpu requests

"""# üîπ Step 2: Full Project Code"""

import requests

MISTRAL_API_KEY = "Y3CyYnKF2bwuj7hX0tAjt3Patj7rHT2D"

API_URL = "https://api.mistral.ai/v1/chat/completions"
headers = {"Authorization": f"Bearer {MISTRAL_API_KEY}", "Content-Type": "application/json"}

payload = {
    "model": "mistral-tiny",
    "messages": [{"role": "user", "content": "Hello, what is AI?"}],
    "temperature": 0.7
}

response = requests.post(API_URL, json=payload, headers=headers)

print(response.json())

import requests
import faiss
import numpy as np
import time
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from youtube_transcript_api import YouTubeTranscriptApi

# ‚úÖ Step 1: Get YouTube Transcript
def get_transcript(video_url):
    video_id = video_url.split("v=")[-1]
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        text = "\n".join([entry['text'] for entry in transcript])
        return text
    except Exception as e:
        return f"Error retrieving transcript: {e}"

video_url = "https://www.youtube.com/watch?v=aqzxYofJ_ck"
transcript_text = get_transcript(video_url)
print("‚úÖ Transcript Retrieved!")

# ‚úÖ Step 2: Split Transcript into Chunks
splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_text(transcript_text)

# ‚úÖ Step 3: Generate Embeddings (Free with Hugging Face)
embedding_model = "sentence-transformers/all-MiniLM-L6-v2"
embeddings = HuggingFaceEmbeddings(model_name=embedding_model)
embedding_vectors = [embeddings.embed_query(chunk) for chunk in chunks]

# ‚úÖ Step 4: Store in FAISS Vector Database
dimension = len(embedding_vectors[0])
faiss_index = faiss.IndexFlatL2(dimension)
faiss_index.add(np.array(embedding_vectors, dtype="float32"))
print("‚úÖ Transcript Indexed Successfully!")

# ‚úÖ Step 5: Answer Questions Using Mistral AI API (Free)
#MISTRAL_API_KEY = "sk-your-valid-mistral-api-key"  # Replace with correct key
MISTRAL_API_KEY = "Y3CyYnKF2bwuj7hX0tAjt3Patj7rHT2D"

def ask_mistral(question, retries=3):
    API_URL = "https://api.mistral.ai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {MISTRAL_API_KEY}", "Content-Type": "application/json"}

    # Retrieve most relevant transcript chunks
    D, I = faiss_index.search(np.array([embeddings.embed_query(question)], dtype="float32"), k=3)
    context = "\n".join([chunks[i] for i in I[0]])

    payload = {
        "model": "mistral-tiny",
        "messages": [
            {"role": "system", "content": "You are an AI assistant answering questions based on a video transcript."},
            {"role": "user", "content": f"Based on this transcript:\n{context}\n\nAnswer this: {question}"}
        ],
        "temperature": 0.7
    }

    for attempt in range(retries):
        try:
            response = requests.post(API_URL, json=payload, headers=headers, timeout=10)
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            else:
                print(f"‚ùå API Error: {response.text}")
        except requests.exceptions.RequestException as e:
            print(f"‚ö†Ô∏è Request failed: {e}, retrying... ({attempt + 1}/{retries})")
            time.sleep(2)  # Wait before retrying

    return "Error: Unable to get a response from Mistral API."

# Example: Ask a Question
question = "What does the video say about AI?"
answer = ask_mistral(question)
print("\nüí° Answer:", answer)



"""# 5Ô∏è‚É£ Building a Web App (Optional)

To make the bot interactive, you can deploy it using Streamlit:
"""

pip install streamlit

"""# üîπ Full Streamlit App Code (app.py)"""

import streamlit as st
import requests
import faiss
import numpy as np
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from youtube_transcript_api import YouTubeTranscriptApi

# ‚úÖ **Step 1: Get YouTube Transcript**
def get_transcript(video_url):
    try:
        video_id = video_url.split("v=")[-1]  # Extract video ID
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        text = "\n".join([entry['text'] for entry in transcript])
        return text
    except Exception as e:
        return f"Error retrieving transcript: {e}"

# ‚úÖ **Step 2: Generate Embeddings**
def create_vector_index(text):
    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = splitter.split_text(text)

    embedding_model = "BAAI/bge-small-en"  # Optimized for retrieval
    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)

    embedding_vectors = [embeddings.embed_query(chunk) for chunk in chunks]

    # Create FAISS index
    dimension = len(embedding_vectors[0])
    faiss_index = faiss.IndexFlatL2(dimension)
    faiss_index.add(np.array(embedding_vectors, dtype="float32"))

    return chunks, embeddings, faiss_index

# ‚úÖ **Step 3: Ask Mistral AI**
MISTRAL_API_KEY = "sk-your-mistral-api-key"  # Replace with a valid API key

def ask_mistral(question, faiss_index, chunks, embeddings):
    API_URL = "https://api.mistral.ai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {MISTRAL_API_KEY}", "Content-Type": "application/json"}

    # Retrieve most relevant transcript chunks
    D, I = faiss_index.search(np.array([embeddings.embed_query(question)], dtype="float32"), k=3)
    context = "\n".join([chunks[i] for i in I[0]])

    payload = {
        "model": "mistral-tiny",
        "messages": [
            {"role": "system", "content": "You are an AI assistant answering questions based on a video transcript."},
            {"role": "user", "content": f"Based on this transcript:\n{context}\n\nAnswer this: {question}"}
        ],
        "temperature": 0.7
    }

    response = requests.post(API_URL, json=payload, headers=headers)

    if response.status_code == 200:
        return response.json()["choices"][0]["message"]["content"]
    else:
        return f"Error: {response.text}"

# ‚úÖ **Step 4: Build Streamlit Web App**
st.title("üì∫ YouTube Q&A Bot with Mistral AI")
st.write("Enter a YouTube video URL, then ask a question about its content.")

video_url = st.text_input("üîó Enter YouTube Video URL:")
question = st.text_input("‚ùì Ask a question about the video:")

if st.button("Generate Answer"):
    if video_url:
        st.write("üì• Retrieving transcript...")
        transcript_text = get_transcript(video_url)

        if "Error" not in transcript_text:
            st.write("üìä Processing transcript embeddings...")
            chunks, embeddings, faiss_index = create_vector_index(transcript_text)

            st.write("ü§ñ Generating answer from Mistral AI...")
            answer = ask_mistral(question, faiss_index, chunks, embeddings)

            st.success("‚úÖ Answer:")
            st.write(answer)
        else:
            st.error("üö® Unable to retrieve transcript. Try another video.")
    else:
        st.warning("‚ö†Ô∏è Please enter a valid YouTube video URL.")

"""# üîπ How to Run the Web App

Save the code as app.py and run:
"""

streamlit run app.py & npx localtunnel --port 8501





"""# Building a Web interface"""

!pip install gradio yt-dlp youtube-transcript-api langchain faiss-cpu sentence-transformers requests

import gradio as gr
import requests
import faiss
import numpy as np
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from youtube_transcript_api import YouTubeTranscriptApi

# ‚úÖ Step 1: Get YouTube Transcript
def get_transcript(video_url):
    try:
        video_id = video_url.split("v=")[-1]  # Extract video ID
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        text = "\n".join([entry['text'] for entry in transcript])
        return text
    except Exception as e:
        return f"Error retrieving transcript: {e}"

# ‚úÖ Step 2: Generate Embeddings
def create_vector_index(text):
    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = splitter.split_text(text)

    embedding_model = "BAAI/bge-small-en"  # Optimized for retrieval
    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)

    embedding_vectors = [embeddings.embed_query(chunk) for chunk in chunks]

    # Create FAISS index
    dimension = len(embedding_vectors[0])
    faiss_index = faiss.IndexFlatL2(dimension)
    faiss_index.add(np.array(embedding_vectors, dtype="float32"))

    return chunks, embeddings, faiss_index

# ‚úÖ Step 3: Ask Mistral AI
MISTRAL_API_KEY = "sk-your-mistral-api-key"  # Replace with a valid API key

def ask_mistral(video_url, question):
    transcript_text = get_transcript(video_url)
    if "Error" in transcript_text:
        return "üö® Unable to retrieve transcript. Try another video."

    chunks, embeddings, faiss_index = create_vector_index(transcript_text)

    API_URL = "https://api.mistral.ai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {MISTRAL_API_KEY}", "Content-Type": "application/json"}

    # Retrieve most relevant transcript chunks
    D, I = faiss_index.search(np.array([embeddings.embed_query(question)], dtype="float32"), k=3)
    context = "\n".join([chunks[i] for i in I[0]])

    payload = {
        "model": "mistral-tiny",
        "messages": [
            {"role": "system", "content": "You are an AI assistant answering questions based on a video transcript."},
            {"role": "user", "content": f"Based on this transcript:\n{context}\n\nAnswer this: {question}"}
        ],
        "temperature": 0.7
    }

    response = requests.post(API_URL, json=payload, headers=headers)

    if response.status_code == 200:
        return response.json()["choices"][0]["message"]["content"]
    else:
        return f"Error: {response.text}"

# ‚úÖ Step 4: Build Gradio Web Interface
app = gr.Interface(
    fn=ask_mistral,
    inputs=[gr.Textbox(label="Enter YouTube Video URL"), gr.Textbox(label="Ask a question about the video")],
    outputs="text",
    title="üì∫ YouTube Q&A Bot with Mistral AI",
    description="Enter a YouTube video URL and ask a question about its content. The bot will retrieve the transcript, process it, and generate an answer using Mistral AI.",
)

# ‚úÖ Step 5: Launch in Google Colab
app.launch(share=True)

Running on public URL: https://your-gradio-link.gradio.live

